{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdef77dd-0ecc-4804-9d8e-6cbc36d8fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\gandh\\anaconda3\\lib\\site-packages (1.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~nnxruntime (C:\\Users\\gandh\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~nnxruntime (C:\\Users\\gandh\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb898aa9-da73-4e31-a5cd-9c96fe8d08ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 17012 words\n",
      "First 10 words: ['vol', 'information', 'systems', 'frontiers', 'httpsdoiorgs', 'generative', 'artificial', 'intelligence', 'evolving', 'technology']\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Cell 2: Read and clean text from a PDF file\n",
    "def read_and_clean_pdf(filename):\n",
    "    doc = fitz.open(filename)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    # Clean text: remove special characters and digits, convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Split into words and filter out empty strings\n",
    "    words = [word for word in text.split() if word]\n",
    "    \n",
    "    return words\n",
    "\n",
    "corpus = read_and_clean_pdf(\"C:\\\\Users\\\\gandh\\\\Downloads\\\\Generative_Artificial_Intelligence_Evolving_Techno.pdf\")\n",
    "print(f\"Corpus size: {len(corpus)} words\")\n",
    "print(f\"First 10 words: {corpus[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2cc8105-7189-49e1-aad0-ef39b22f842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial vocabulary (first 10 entries):\n",
      "('v', 'o', 'l', '</w>'): 4\n",
      "('i', 'n', 'f', 'o', 'r', 'm', 'a', 't', 'i', 'o', 'n', '</w>'): 122\n",
      "('s', 'y', 's', 't', 'e', 'm', 's', '</w>'): 267\n",
      "('f', 'r', 'o', 'n', 't', 'i', 'e', 'r', 's', '</w>'): 25\n",
      "('h', 't', 't', 'p', 's', 'd', 'o', 'i', 'o', 'r', 'g', 's', '</w>'): 1\n",
      "('g', 'e', 'n', 'e', 'r', 'a', 't', 'i', 'v', 'e', '</w>'): 58\n",
      "('a', 'r', 't', 'i', 'f', 'i', 'c', 'i', 'a', 'l', '</w>'): 38\n",
      "('i', 'n', 't', 'e', 'l', 'l', 'i', 'g', 'e', 'n', 'c', 'e', '</w>'): 38\n",
      "('e', 'v', 'o', 'l', 'v', 'i', 'n', 'g', '</w>'): 2\n",
      "('t', 'e', 'c', 'h', 'n', 'o', 'l', 'o', 'g', 'y', '</w>'): 56\n",
      "\n",
      "Total unique words: 3478\n"
     ]
    }
   ],
   "source": [
    "def preprocess_for_bpe(corpus):\n",
    "    word_freqs = defaultdict(int)\n",
    "    \n",
    "    for word in corpus:\n",
    "        word_freqs[word] += 1\n",
    "    \n",
    "    vocab = defaultdict(int)\n",
    "    \n",
    "    for word, freq in word_freqs.items():\n",
    "        # Break word into characters and add end-of-word marker\n",
    "        word_tokens = tuple(list(word) + ['</w>'])\n",
    "        vocab[word_tokens] += freq\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "vocab = preprocess_for_bpe(corpus)\n",
    "print(\"Initial vocabulary (first 10 entries):\")\n",
    "for i, (word_tokens, freq) in enumerate(vocab.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"{word_tokens}: {freq}\")\n",
    "\n",
    "print(f\"\\nTotal unique words: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ed19bc-35f6-462a-a4f5-7aa5775f789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pairs (top 10):\n",
      "('s', '</w>'): 2890\n",
      "('e', '</w>'): 2672\n",
      "('i', 'n'): 1973\n",
      "('a', 'n'): 1671\n",
      "('o', 'n'): 1612\n",
      "('n', '</w>'): 1590\n",
      "('t', 'i'): 1518\n",
      "('e', 'r'): 1495\n",
      "('t', 'h'): 1439\n",
      "('d', '</w>'): 1369\n"
     ]
    }
   ],
   "source": [
    "def get_pair_frequencies(vocab):\n",
    "    pairs = defaultdict(int)\n",
    "    for word_tokens, freq in vocab.items():\n",
    "        for i in range(len(word_tokens) - 1):\n",
    "            pair = (word_tokens[i], word_tokens[i + 1])\n",
    "            pairs[pair] += freq\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Test the function\n",
    "pair_freqs = get_pair_frequencies(vocab)\n",
    "print(\"Most frequent pairs (top 10):\")\n",
    "for pair, freq in sorted(pair_freqs.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{pair}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6249e1-6316-4f5e-8db7-79666d31313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing merge of pair: ('s', '</w>')\n",
      "Vocabulary size before merge: 3478\n",
      "Vocabulary size after merge: 3478\n"
     ]
    }
   ],
   "source": [
    "def merge_pair(pair, vocab):\n",
    "    new_vocab = defaultdict(int)\n",
    "    \n",
    "    for word_tokens, freq in vocab.items():\n",
    "        new_word_tokens = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(word_tokens):\n",
    "            if i < len(word_tokens) - 1 and (word_tokens[i], word_tokens[i + 1]) == pair:\n",
    "                # Merge the pair\n",
    "                merged_token = word_tokens[i] + word_tokens[i + 1]\n",
    "                new_word_tokens.append(merged_token)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word_tokens.append(word_tokens[i])\n",
    "                i += 1\n",
    "        \n",
    "        new_vocab[tuple(new_word_tokens)] += freq\n",
    "    \n",
    "    return new_vocab\n",
    "\n",
    "# Test merge function\n",
    "test_pair = max(pair_freqs.items(), key=lambda x: x[1])[0]\n",
    "print(f\"Testing merge of pair: {test_pair}\")\n",
    "merged_vocab = merge_pair(test_pair, vocab)\n",
    "print(f\"Vocabulary size before merge: {len(vocab)}\")\n",
    "print(f\"Vocabulary size after merge: {len(merged_vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6175ea7e-298e-4843-b278-b633acccc9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1: ('s', '</w>') (frequency: 2890)\n",
      "Merge 2: ('e', '</w>') (frequency: 2672)\n",
      "Merge 3: ('i', 'n') (frequency: 1973)\n",
      "Merge 4: ('a', 'n') (frequency: 1671)\n",
      "Merge 5: ('o', 'n') (frequency: 1612)\n",
      "Merge 6: ('e', 'r') (frequency: 1495)\n",
      "Merge 7: ('t', 'h') (frequency: 1439)\n",
      "Merge 8: ('t', 'i') (frequency: 1394)\n",
      "Merge 9: ('d', '</w>') (frequency: 1369)\n",
      "Merge 10: ('e', 'n') (frequency: 1338)\n",
      "Merge 11: ('t', '</w>') (frequency: 1240)\n",
      "Merge 12: ('o', 'r') (frequency: 1070)\n",
      "Merge 13: ('a', 'l') (frequency: 976)\n",
      "Merge 14: ('y', '</w>') (frequency: 944)\n",
      "Merge 15: ('a', 'r') (frequency: 886)\n",
      "Merge 16: ('t', 'e') (frequency: 854)\n",
      "Merge 17: ('r', 'e') (frequency: 806)\n",
      "Merge 18: ('ti', 'on') (frequency: 777)\n",
      "Merge 19: ('c', 'h') (frequency: 752)\n",
      "Merge 20: ('g', '</w>') (frequency: 738)\n",
      "Merge 21: ('o', 'f') (frequency: 730)\n",
      "Merge 22: ('th', 'e</w>') (frequency: 689)\n",
      "Merge 23: ('of', '</w>') (frequency: 684)\n",
      "Merge 24: ('an', 'd</w>') (frequency: 644)\n",
      "Merge 25: ('al', '</w>') (frequency: 636)\n",
      "Merge 26: ('o', '</w>') (frequency: 569)\n",
      "Merge 27: ('in', 'g</w>') (frequency: 563)\n",
      "Merge 28: ('a', '</w>') (frequency: 538)\n",
      "Merge 29: ('e', 's</w>') (frequency: 514)\n",
      "Merge 30: ('a', 'tion') (frequency: 500)\n",
      "Merge 31: ('i', '</w>') (frequency: 491)\n",
      "Merge 32: ('r', 'o') (frequency: 485)\n",
      "Merge 33: ('t', 'o</w>') (frequency: 431)\n",
      "Merge 34: ('g', 'en') (frequency: 425)\n",
      "Merge 35: ('e', 's') (frequency: 418)\n",
      "Merge 36: ('a', 't') (frequency: 416)\n",
      "Merge 37: ('i', 'c') (frequency: 404)\n",
      "Merge 38: ('in', '</w>') (frequency: 397)\n",
      "Merge 39: ('f', 'or') (frequency: 394)\n",
      "Merge 40: ('m', 's</w>') (frequency: 391)\n",
      "Merge 41: ('er', '</w>') (frequency: 384)\n",
      "Merge 42: ('c', 'o') (frequency: 381)\n",
      "Merge 43: ('a', 'i</w>') (frequency: 377)\n",
      "Merge 44: ('e', 'd</w>') (frequency: 374)\n",
      "Merge 45: ('s', 'y') (frequency: 353)\n",
      "Merge 46: ('i', 's</w>') (frequency: 349)\n",
      "Merge 47: ('u', 'r') (frequency: 346)\n",
      "Merge 48: ('e', 'l') (frequency: 330)\n",
      "Merge 49: ('s', 'te') (frequency: 329)\n",
      "Merge 50: ('m', 'p') (frequency: 326)\n",
      "Merge 51: ('u', 's') (frequency: 326)\n",
      "Merge 52: ('sy', 'ste') (frequency: 324)\n",
      "Merge 53: ('t', 's</w>') (frequency: 322)\n",
      "Merge 54: ('c', 'on') (frequency: 318)\n",
      "Merge 55: ('ation', '</w>') (frequency: 317)\n",
      "Merge 56: ('m', '</w>') (frequency: 303)\n",
      "Merge 57: ('i', 's') (frequency: 291)\n",
      "Merge 58: ('re', 's') (frequency: 285)\n",
      "Merge 59: ('l', 'e') (frequency: 282)\n",
      "Merge 60: ('an', '</w>') (frequency: 278)\n",
      "Merge 61: ('ch', '</w>') (frequency: 270)\n",
      "Merge 62: ('syste', 'ms</w>') (frequency: 268)\n",
      "Merge 63: ('u', 'n') (frequency: 267)\n",
      "Merge 64: ('a', 'c') (frequency: 266)\n",
      "Merge 65: ('p', 'ro') (frequency: 263)\n",
      "Merge 66: ('a', 's') (frequency: 257)\n",
      "Merge 67: ('t', 'r') (frequency: 244)\n",
      "Merge 68: ('v', 'e</w>') (frequency: 235)\n",
      "Merge 69: ('on', '</w>') (frequency: 233)\n",
      "Merge 70: ('o', 'l') (frequency: 229)\n",
      "Merge 71: ('s', 'i') (frequency: 229)\n",
      "Merge 72: ('en', 't</w>') (frequency: 229)\n",
      "Merge 73: ('g', 'e</w>') (frequency: 225)\n",
      "Merge 74: ('m', 'a') (frequency: 219)\n",
      "Merge 75: ('e', 'c') (frequency: 215)\n",
      "Merge 76: ('i', 'l') (frequency: 213)\n",
      "Merge 77: ('a', 's</w>') (frequency: 212)\n",
      "Merge 78: ('c', 'e</w>') (frequency: 204)\n",
      "Merge 79: ('l', 'y</w>') (frequency: 200)\n",
      "Merge 80: ('a', 'p') (frequency: 195)\n",
      "Merge 81: ('o', 'w') (frequency: 191)\n",
      "Merge 82: ('i', 't') (frequency: 189)\n",
      "Merge 83: ('o', 'p') (frequency: 186)\n",
      "Merge 84: ('t', 'er') (frequency: 183)\n",
      "Merge 85: ('a', 't</w>') (frequency: 179)\n",
      "Merge 86: ('a', 'd') (frequency: 178)\n",
      "Merge 87: ('gen', 'ai</w>') (frequency: 177)\n",
      "Merge 88: ('e', 'ar') (frequency: 176)\n",
      "Merge 89: ('s', 'u') (frequency: 175)\n",
      "Merge 90: ('a', 'b') (frequency: 173)\n",
      "Merge 91: ('u', 'l') (frequency: 172)\n",
      "Merge 92: ('for', 'm') (frequency: 169)\n",
      "Merge 93: ('n', 'e') (frequency: 166)\n",
      "Merge 94: ('c', 'i') (frequency: 163)\n",
      "Merge 95: ('or', '</w>') (frequency: 163)\n",
      "Merge 96: ('e', 'x') (frequency: 160)\n",
      "Merge 97: ('d', 'e') (frequency: 157)\n",
      "Merge 98: ('u', 'm') (frequency: 157)\n",
      "Merge 99: ('ti', 've</w>') (frequency: 156)\n",
      "Merge 100: ('for', '</w>') (frequency: 156)\n",
      "Merge 101: ('p', 'er') (frequency: 154)\n",
      "Merge 102: ('s', 't') (frequency: 150)\n",
      "Merge 103: ('i', 'th') (frequency: 147)\n",
      "Merge 104: ('tion', '</w>') (frequency: 146)\n",
      "Merge 105: ('l', 'e</w>') (frequency: 142)\n",
      "Merge 106: ('p', 'r') (frequency: 140)\n",
      "Merge 107: ('o', 'u') (frequency: 137)\n",
      "Merge 108: ('i', 'g') (frequency: 137)\n",
      "Merge 109: ('form', 'ation</w>') (frequency: 136)\n",
      "Merge 110: ('res', 'ear') (frequency: 136)\n",
      "Merge 111: ('h', 'um') (frequency: 136)\n",
      "Merge 112: ('l', '</w>') (frequency: 136)\n",
      "Merge 113: ('te', 'ch') (frequency: 132)\n",
      "Merge 114: ('e', 'm') (frequency: 131)\n",
      "Merge 115: ('tech', 'n') (frequency: 130)\n",
      "Merge 116: ('w', 'h') (frequency: 130)\n",
      "Merge 117: ('in', 'formation</w>') (frequency: 128)\n",
      "Merge 118: ('er', 's</w>') (frequency: 127)\n",
      "Merge 119: ('l', 'i') (frequency: 127)\n",
      "Merge 120: ('te', 'd</w>') (frequency: 126)\n",
      "Merge 121: ('w', 'ith') (frequency: 125)\n",
      "Merge 122: ('co', 'mp') (frequency: 125)\n",
      "Merge 123: ('gen', 'er') (frequency: 120)\n",
      "Merge 124: ('o', 'd') (frequency: 119)\n",
      "Merge 125: ('i', 'mp') (frequency: 116)\n",
      "Merge 126: ('ation', 's</w>') (frequency: 116)\n",
      "Merge 127: ('i', 'z') (frequency: 115)\n",
      "Merge 128: ('v', 'i') (frequency: 115)\n",
      "Merge 129: ('un', 'd') (frequency: 114)\n",
      "Merge 130: ('es', 's</w>') (frequency: 111)\n",
      "Merge 131: ('a', 'm') (frequency: 111)\n",
      "Merge 132: ('s', 'o') (frequency: 110)\n",
      "Merge 133: ('o', 'g') (frequency: 109)\n",
      "Merge 134: ('ar', 'e</w>') (frequency: 109)\n",
      "Merge 135: ('k', '</w>') (frequency: 109)\n",
      "Merge 136: ('q', 'u') (frequency: 109)\n",
      "Merge 137: ('d', 'i') (frequency: 109)\n",
      "Merge 138: ('p', 'l') (frequency: 108)\n",
      "Merge 139: ('resear', 'ch</w>') (frequency: 107)\n",
      "Merge 140: ('th', 'at</w>') (frequency: 107)\n",
      "Merge 141: ('f', 'ic') (frequency: 106)\n",
      "Merge 142: ('ur', 'e</w>') (frequency: 105)\n",
      "Merge 143: ('en', '</w>') (frequency: 105)\n",
      "Merge 144: ('it', 'y</w>') (frequency: 103)\n",
      "Merge 145: ('th', 'e') (frequency: 101)\n",
      "Merge 146: ('w', '</w>') (frequency: 100)\n",
      "Merge 147: ('e', 't</w>') (frequency: 100)\n",
      "Merge 148: ('with', '</w>') (frequency: 99)\n",
      "Merge 149: ('w', 'or') (frequency: 99)\n",
      "Merge 150: ('in', 'g') (frequency: 98)\n",
      "Merge 151: ('b', 'e') (frequency: 96)\n",
      "Merge 152: ('v', 'el') (frequency: 94)\n",
      "Merge 153: ('a', 'ge</w>') (frequency: 94)\n",
      "Merge 154: ('p', 'o') (frequency: 94)\n",
      "Merge 155: ('co', 'm') (frequency: 94)\n",
      "Merge 156: ('e', 'p') (frequency: 93)\n",
      "Merge 157: ('ti', 'c') (frequency: 93)\n",
      "Merge 158: ('v', 'er') (frequency: 93)\n",
      "Merge 159: ('a', 'tive</w>') (frequency: 92)\n",
      "Merge 160: ('m', 'od') (frequency: 91)\n",
      "Merge 161: ('ol', 'og') (frequency: 90)\n",
      "Merge 162: ('n', '</w>') (frequency: 89)\n",
      "Merge 163: ('n', 'at') (frequency: 89)\n",
      "Merge 164: ('ti', 'es</w>') (frequency: 87)\n",
      "Merge 165: ('n', 'o') (frequency: 86)\n",
      "Merge 166: ('es', 's') (frequency: 86)\n",
      "Merge 167: ('mod', 'el') (frequency: 85)\n",
      "Merge 168: ('th', 'is</w>') (frequency: 85)\n",
      "Merge 169: ('i', 't</w>') (frequency: 85)\n",
      "Merge 170: ('at', 'e</w>') (frequency: 85)\n",
      "Merge 171: ('h', 'a') (frequency: 83)\n",
      "Merge 172: ('so', 'ci') (frequency: 82)\n",
      "Merge 173: ('m', 'an') (frequency: 82)\n",
      "Merge 174: ('d', 'u') (frequency: 82)\n",
      "Merge 175: ('techn', 'olog') (frequency: 81)\n",
      "Merge 176: ('g', 'u') (frequency: 81)\n",
      "Merge 177: ('b', 'e</w>') (frequency: 81)\n",
      "Merge 178: ('p', 'u') (frequency: 81)\n",
      "Merge 179: ('c', 'an</w>') (frequency: 80)\n",
      "Merge 180: ('b', 'y</w>') (frequency: 79)\n",
      "Merge 181: ('p', 'ar') (frequency: 79)\n",
      "Merge 182: ('a', 'g') (frequency: 79)\n",
      "Merge 183: ('d', 'at') (frequency: 79)\n",
      "Merge 184: ('h', 'ow') (frequency: 78)\n",
      "Merge 185: ('c', 're') (frequency: 78)\n",
      "Merge 186: ('i', 'r') (frequency: 78)\n",
      "Merge 187: ('in', 'te') (frequency: 77)\n",
      "Merge 188: ('con', 't') (frequency: 76)\n",
      "Merge 189: ('p', 'ec') (frequency: 76)\n",
      "Merge 190: ('u', 't') (frequency: 76)\n",
      "Merge 191: ('f', 'ro') (frequency: 75)\n",
      "Merge 192: ('fro', 'm</w>') (frequency: 75)\n",
      "Merge 193: ('us', 'e</w>') (frequency: 75)\n",
      "Merge 194: ('hum', 'an</w>') (frequency: 75)\n",
      "Merge 195: ('t', 'y</w>') (frequency: 74)\n",
      "Merge 196: ('pro', 'c') (frequency: 74)\n",
      "Merge 197: ('l', 'l') (frequency: 72)\n",
      "Merge 198: ('ic', 'al</w>') (frequency: 71)\n",
      "Merge 199: ('en', 'ce</w>') (frequency: 71)\n",
      "Merge 200: ('b', 'as') (frequency: 71)\n",
      "Merge 201: ('l', 'u') (frequency: 69)\n",
      "Merge 202: ('le', 'ar') (frequency: 69)\n",
      "Merge 203: ('t', 'u') (frequency: 69)\n",
      "Merge 204: ('in', 'ter') (frequency: 69)\n",
      "Merge 205: ('or', 'g') (frequency: 68)\n",
      "Merge 206: ('m', 'e') (frequency: 68)\n",
      "Merge 207: ('m', 'ent</w>') (frequency: 67)\n",
      "Merge 208: ('s', 'h') (frequency: 67)\n",
      "Merge 209: ('tion', 's</w>') (frequency: 67)\n",
      "Merge 210: ('l', 'an') (frequency: 66)\n",
      "Merge 211: ('dat', 'a</w>') (frequency: 66)\n",
      "Merge 212: ('e', 'v') (frequency: 65)\n",
      "Merge 213: ('p', 'or') (frequency: 65)\n",
      "Merge 214: ('n', 'ing</w>') (frequency: 65)\n",
      "Merge 215: ('gu', 'age</w>') (frequency: 64)\n",
      "Merge 216: ('in', 'e</w>') (frequency: 64)\n",
      "Merge 217: ('ic', '</w>') (frequency: 64)\n",
      "Merge 218: ('ne', 'w</w>') (frequency: 63)\n",
      "Merge 219: ('o', 'th') (frequency: 63)\n",
      "Merge 220: ('org', 'an') (frequency: 62)\n",
      "Merge 221: ('nat', 'ure</w>') (frequency: 62)\n",
      "Merge 222: ('i', 'al</w>') (frequency: 61)\n",
      "Merge 223: ('p', 're') (frequency: 61)\n",
      "Merge 224: ('i', 'd') (frequency: 61)\n",
      "Merge 225: ('hum', 'an') (frequency: 61)\n",
      "Merge 226: ('t', 'en') (frequency: 60)\n",
      "Merge 227: ('p', '</w>') (frequency: 60)\n",
      "Merge 228: ('p', 't</w>') (frequency: 60)\n",
      "Merge 229: ('gener', 'ative</w>') (frequency: 59)\n",
      "Merge 230: ('de', 'vel') (frequency: 59)\n",
      "Merge 231: ('lan', 'guage</w>') (frequency: 59)\n",
      "Merge 232: ('organ', 'iz') (frequency: 59)\n",
      "Merge 233: ('ch', 'at') (frequency: 59)\n",
      "Merge 234: ('f', 'r') (frequency: 58)\n",
      "Merge 235: ('technolog', 'y</w>') (frequency: 58)\n",
      "Merge 236: ('j', '</w>') (frequency: 58)\n",
      "Merge 237: ('ation', 'al</w>') (frequency: 58)\n",
      "Merge 238: ('an', 's') (frequency: 58)\n",
      "Merge 239: ('ig', 'h') (frequency: 58)\n",
      "Merge 240: ('devel', 'op') (frequency: 57)\n",
      "Merge 241: ('en', 'ts</w>') (frequency: 57)\n",
      "Merge 242: ('b', 'us') (frequency: 57)\n",
      "Merge 243: ('i', 'ts</w>') (frequency: 57)\n",
      "Merge 244: ('te', 'x') (frequency: 57)\n",
      "Merge 245: ('o', 'ur') (frequency: 57)\n",
      "Merge 246: ('k', 's</w>') (frequency: 57)\n",
      "Merge 247: ('und', 'er') (frequency: 57)\n",
      "Merge 248: ('gen', 'ce</w>') (frequency: 56)\n",
      "Merge 249: ('com', 'm') (frequency: 56)\n",
      "Merge 250: ('su', 'ch</w>') (frequency: 56)\n",
      "Merge 251: ('bas', 'ed</w>') (frequency: 56)\n",
      "Merge 252: ('i', 'v') (frequency: 56)\n",
      "Merge 253: ('ur', 'al</w>') (frequency: 56)\n",
      "Merge 254: ('a', 'ted</w>') (frequency: 55)\n",
      "Merge 255: ('al', 'ly</w>') (frequency: 55)\n",
      "Merge 256: ('how', '</w>') (frequency: 55)\n",
      "Merge 257: ('d', 'is') (frequency: 55)\n",
      "Merge 258: ('th', 'es') (frequency: 55)\n",
      "Merge 259: ('c', 'ep') (frequency: 54)\n",
      "Merge 260: ('under', 'st') (frequency: 54)\n",
      "Merge 261: ('bus', 'in') (frequency: 53)\n",
      "Merge 262: ('ab', 'il') (frequency: 53)\n",
      "Merge 263: ('g', 'pt</w>') (frequency: 53)\n",
      "Merge 264: ('en', 't') (frequency: 53)\n",
      "Merge 265: ('ar', 'ti') (frequency: 52)\n",
      "Merge 266: ('i', 'es</w>') (frequency: 52)\n",
      "Merge 267: ('h', '</w>') (frequency: 52)\n",
      "Merge 268: ('s', 'tr') (frequency: 51)\n",
      "Merge 269: ('lear', 'ning</w>') (frequency: 51)\n",
      "Merge 270: ('d', 'ing</w>') (frequency: 51)\n",
      "Merge 271: ('e', 'd') (frequency: 50)\n",
      "Merge 272: ('i', 'ch</w>') (frequency: 50)\n",
      "Merge 273: ('en', 'g') (frequency: 50)\n",
      "Merge 274: ('g', 'r') (frequency: 50)\n",
      "Merge 275: ('thes', 'e</w>') (frequency: 50)\n",
      "Merge 276: ('inte', 'l') (frequency: 49)\n",
      "Merge 277: ('i', 'ties</w>') (frequency: 49)\n",
      "Merge 278: ('l', 'ar') (frequency: 49)\n",
      "Merge 279: ('busin', 'ess</w>') (frequency: 49)\n",
      "Merge 280: ('t', 'ing</w>') (frequency: 49)\n",
      "Merge 281: ('t', 'o') (frequency: 49)\n",
      "Merge 282: ('wh', 'ich</w>') (frequency: 49)\n",
      "Merge 283: ('po', 's') (frequency: 49)\n",
      "Merge 284: ('pr', 'ing') (frequency: 49)\n",
      "Merge 285: ('ch', 'an') (frequency: 48)\n",
      "Merge 286: ('oth', 'er</w>') (frequency: 48)\n",
      "Merge 287: ('an', 't</w>') (frequency: 48)\n",
      "Merge 288: ('d', 'es') (frequency: 48)\n",
      "Merge 289: ('cont', 'ent</w>') (frequency: 48)\n",
      "Merge 290: ('s', 'pring') (frequency: 48)\n",
      "Merge 291: ('spring', 'er</w>') (frequency: 48)\n",
      "Merge 292: ('chat', 'gpt</w>') (frequency: 48)\n",
      "Merge 293: ('the', 'or') (frequency: 48)\n",
      "Merge 294: ('imp', 'ac') (frequency: 47)\n",
      "Merge 295: ('h', 'as</w>') (frequency: 47)\n",
      "Merge 296: ('s', 'pec') (frequency: 47)\n",
      "Merge 297: ('tr', 'ans') (frequency: 47)\n",
      "Merge 298: ('w', 'il') (frequency: 47)\n",
      "Merge 299: ('n', 'ow') (frequency: 47)\n",
      "Merge 300: ('em', 'ent</w>') (frequency: 47)\n",
      "Merge 301: ('model', 's</w>') (frequency: 46)\n",
      "Merge 302: ('syste', 'm</w>') (frequency: 46)\n",
      "Merge 303: ('on', 'g</w>') (frequency: 46)\n",
      "Merge 304: ('c', 'es</w>') (frequency: 46)\n",
      "Merge 305: ('ma', 'ch') (frequency: 46)\n",
      "Merge 306: ('ab', 'le</w>') (frequency: 46)\n",
      "Merge 307: ('ou', 't') (frequency: 46)\n",
      "Merge 308: ('intel', 'li') (frequency: 45)\n",
      "Merge 309: ('no', 't</w>') (frequency: 44)\n",
      "Merge 310: ('ul', 'd</w>') (frequency: 44)\n",
      "Merge 311: ('wil', 'l</w>') (frequency: 44)\n",
      "Merge 312: ('al', 'l') (frequency: 44)\n",
      "Merge 313: ('k', 'now') (frequency: 44)\n",
      "Merge 314: ('e', 'f') (frequency: 42)\n",
      "Merge 315: ('ap', 'p') (frequency: 42)\n",
      "Merge 316: ('n', 'al</w>') (frequency: 42)\n",
      "Merge 317: ('in', 'c') (frequency: 41)\n",
      "Merge 318: ('w', 'e</w>') (frequency: 41)\n",
      "Merge 319: ('em', 'er') (frequency: 41)\n",
      "Merge 320: ('techn', 'ical</w>') (frequency: 41)\n",
      "Merge 321: ('f', 'er') (frequency: 41)\n",
      "Merge 322: ('f', '</w>') (frequency: 41)\n",
      "Merge 323: ('u', '</w>') (frequency: 41)\n",
      "Merge 324: ('b', 'o') (frequency: 41)\n",
      "Merge 325: ('d', 'e</w>') (frequency: 40)\n",
      "Merge 326: ('f', 'o') (frequency: 40)\n",
      "Merge 327: ('ou', 's</w>') (frequency: 40)\n",
      "Merge 328: ('wor', 'k</w>') (frequency: 40)\n",
      "Merge 329: ('ar', '</w>') (frequency: 40)\n",
      "Merge 330: ('proc', 'ess') (frequency: 40)\n",
      "Merge 331: ('pu', 'ts</w>') (frequency: 40)\n",
      "Merge 332: ('fic', 'ial</w>') (frequency: 39)\n",
      "Merge 333: ('i', 'fic') (frequency: 39)\n",
      "Merge 334: ('p', 'res') (frequency: 39)\n",
      "Merge 335: ('a', 'in') (frequency: 39)\n",
      "Merge 336: ('mach', 'ine</w>') (frequency: 39)\n",
      "Merge 337: ('arti', 'ficial</w>') (frequency: 38)\n",
      "Merge 338: ('intelli', 'gence</w>') (frequency: 38)\n",
      "Merge 339: ('or', 'e</w>') (frequency: 38)\n",
      "Merge 340: ('n', 'ec') (frequency: 38)\n",
      "Merge 341: ('du', 'c') (frequency: 38)\n",
      "Merge 342: ('er', 'e</w>') (frequency: 38)\n",
      "Merge 343: ('le', 'd') (frequency: 38)\n",
      "Merge 344: ('c', '</w>') (frequency: 37)\n",
      "Merge 345: ('r', 'a') (frequency: 37)\n",
      "Merge 346: ('an', 'ce</w>') (frequency: 37)\n",
      "Merge 347: ('v', 'ed</w>') (frequency: 37)\n",
      "Merge 348: ('c', 'ap') (frequency: 37)\n",
      "Merge 349: ('j', 'our') (frequency: 37)\n",
      "Merge 350: ('know', 'led') (frequency: 37)\n",
      "Merge 351: ('con', 'cep') (frequency: 37)\n",
      "Merge 352: ('man', 'ag') (frequency: 37)\n",
      "Merge 353: ('an', 'g</w>') (frequency: 37)\n",
      "Merge 354: ('d', 'o') (frequency: 36)\n",
      "Merge 355: ('lar', 'ge</w>') (frequency: 36)\n",
      "Merge 356: ('re', 'c') (frequency: 36)\n",
      "Merge 357: ('ir', '</w>') (frequency: 36)\n",
      "Merge 358: ('b', 'u') (frequency: 35)\n",
      "Merge 359: ('tex', 't</w>') (frequency: 35)\n",
      "Merge 360: ('ha', 've</w>') (frequency: 35)\n",
      "Merge 361: ('des', 'ig') (frequency: 35)\n",
      "Merge 362: ('ter', 'ms</w>') (frequency: 35)\n",
      "Merge 363: ('en', 'ti') (frequency: 35)\n",
      "Merge 364: ('a', 'mp') (frequency: 35)\n",
      "Merge 365: ('ic', 'ations</w>') (frequency: 35)\n",
      "Merge 366: ('t', 'un') (frequency: 34)\n",
      "Merge 367: ('d', 's</w>') (frequency: 34)\n",
      "Merge 368: ('pro', 'per') (frequency: 34)\n",
      "Merge 369: ('s', 'ch') (frequency: 34)\n",
      "Merge 370: ('underst', 'and</w>') (frequency: 34)\n",
      "Merge 371: ('f', 'ac') (frequency: 34)\n",
      "Merge 372: ('develop', 'ment</w>') (frequency: 34)\n",
      "Merge 373: ('knowled', 'ge</w>') (frequency: 34)\n",
      "Merge 374: ('r', '</w>') (frequency: 34)\n",
      "Merge 375: ('g', 'n') (frequency: 33)\n",
      "Merge 376: ('tu', 'al</w>') (frequency: 33)\n",
      "Merge 377: ('te', 's') (frequency: 33)\n",
      "Merge 378: ('wh', 'at</w>') (frequency: 33)\n",
      "Merge 379: ('tion', 'al</w>') (frequency: 33)\n",
      "Merge 380: ('re', 'l') (frequency: 32)\n",
      "Merge 381: ('o', 'm') (frequency: 32)\n",
      "Merge 382: ('ma', 'y</w>') (frequency: 32)\n",
      "Merge 383: ('k', 'e</w>') (frequency: 32)\n",
      "Merge 384: ('ar', 'y</w>') (frequency: 31)\n",
      "Merge 385: ('con', 'nec') (frequency: 31)\n",
      "Merge 386: ('comp', 'ut') (frequency: 31)\n",
      "Merge 387: ('comp', 'le') (frequency: 31)\n",
      "Merge 388: ('s', 'e') (frequency: 31)\n",
      "Merge 389: ('b', '</w>') (frequency: 31)\n",
      "Merge 390: ('m', 'ore</w>') (frequency: 31)\n",
      "Merge 391: ('r', 'i') (frequency: 31)\n",
      "Merge 392: ('the', 'ir</w>') (frequency: 31)\n",
      "Merge 393: ('impac', 't</w>') (frequency: 30)\n",
      "Merge 394: ('w', 'e') (frequency: 30)\n",
      "Merge 395: ('o', 's') (frequency: 30)\n",
      "Merge 396: ('organiz', 'ational</w>') (frequency: 30)\n",
      "Merge 397: ('abil', 'ity</w>') (frequency: 30)\n",
      "Merge 398: ('s', 'ci') (frequency: 30)\n",
      "Merge 399: ('ad', 'v') (frequency: 30)\n",
      "Merge 400: ('r', 'igh') (frequency: 30)\n",
      "Merge 401: ('g', 'o') (frequency: 30)\n",
      "Merge 402: ('ne', 'ural</w>') (frequency: 30)\n",
      "Merge 403: ('ll', 'ms</w>') (frequency: 30)\n",
      "Merge 404: ('p', 'on') (frequency: 30)\n",
      "Merge 405: ('jour', 'nal</w>') (frequency: 30)\n",
      "Merge 406: ('resear', 'ch') (frequency: 29)\n",
      "Merge 407: ('su', 'p') (frequency: 29)\n",
      "Merge 408: ('am', 'e') (frequency: 29)\n",
      "Merge 409: ('a', 'y') (frequency: 29)\n",
      "Merge 410: ('si', 'b') (frequency: 29)\n",
      "Merge 411: ('k', 'ing</w>') (frequency: 29)\n",
      "Merge 412: ('b', 'i') (frequency: 29)\n",
      "Merge 413: ('desig', 'n</w>') (frequency: 29)\n",
      "Merge 414: ('ex', 'amp') (frequency: 29)\n",
      "Merge 415: ('qu', 'es') (frequency: 29)\n",
      "Merge 416: ('theor', 'y</w>') (frequency: 29)\n",
      "Merge 417: ('fr', 'on') (frequency: 28)\n",
      "Merge 418: ('soci', 'e') (frequency: 28)\n",
      "Merge 419: ('op', 'por') (frequency: 28)\n",
      "Merge 420: ('oppor', 'tun') (frequency: 28)\n",
      "Merge 421: ('inc', 'lu') (frequency: 28)\n",
      "Merge 422: ('adv', 'an') (frequency: 28)\n",
      "Merge 423: ('us', 'ed</w>') (frequency: 28)\n",
      "Merge 424: ('i', 'ma') (frequency: 28)\n",
      "Merge 425: ('e', 'g</w>') (frequency: 28)\n",
      "Merge 426: ('res', 'pon') (frequency: 28)\n",
      "Merge 427: ('gen', 't</w>') (frequency: 28)\n",
      "Merge 428: ('manag', 'ement</w>') (frequency: 28)\n",
      "Merge 429: ('fron', 'ti') (frequency: 27)\n",
      "Merge 430: ('ex', 'pl') (frequency: 27)\n",
      "Merge 431: ('research', 'ers</w>') (frequency: 27)\n",
      "Merge 432: ('sup', 'por') (frequency: 27)\n",
      "Merge 433: ('a', 'te') (frequency: 27)\n",
      "Merge 434: ('t', 'as') (frequency: 27)\n",
      "Merge 435: ('ur', 'ing</w>') (frequency: 27)\n",
      "Merge 436: ('co', 'ur') (frequency: 27)\n",
      "Merge 437: ('ne', 't') (frequency: 27)\n",
      "Merge 438: ('s', 'o</w>') (frequency: 27)\n",
      "Merge 439: ('ch', 'all') (frequency: 27)\n",
      "Merge 440: ('is', 'su') (frequency: 27)\n",
      "Merge 441: ('w', 'ar') (frequency: 27)\n",
      "Merge 442: ('a', 'u') (frequency: 26)\n",
      "Merge 443: ('de', 'ep') (frequency: 26)\n",
      "Merge 444: ('i', 'm') (frequency: 26)\n",
      "Merge 445: ('s', 'el') (frequency: 26)\n",
      "Merge 446: ('or', 't') (frequency: 26)\n",
      "Merge 447: ('pu', 't</w>') (frequency: 26)\n",
      "Merge 448: ('en', 'd') (frequency: 26)\n",
      "Merge 449: ('comp', 'on') (frequency: 26)\n",
      "Merge 450: ('t', 'e</w>') (frequency: 26)\n",
      "Merge 451: ('ap', 'pro') (frequency: 26)\n",
      "Merge 452: ('us', 'ers</w>') (frequency: 26)\n",
      "Merge 453: ('fronti', 'ers</w>') (frequency: 25)\n",
      "Merge 454: ('po', 'ten') (frequency: 25)\n",
      "Merge 455: ('poten', 'ti') (frequency: 25)\n",
      "Merge 456: ('si', 'd') (frequency: 25)\n",
      "Merge 457: ('un', 'i') (frequency: 25)\n",
      "Merge 458: ('a', 'y</w>') (frequency: 25)\n",
      "Merge 459: ('u', 'c') (frequency: 25)\n",
      "Merge 460: ('re', 'qu') (frequency: 25)\n",
      "Merge 461: ('l', 'ow') (frequency: 25)\n",
      "Merge 462: ('tic', 'al</w>') (frequency: 25)\n",
      "Merge 463: ('ver', 'si') (frequency: 25)\n",
      "Merge 464: ('app', 'ly</w>') (frequency: 25)\n",
      "Merge 465: ('pro', 'duc') (frequency: 25)\n",
      "Merge 466: ('comple', 'x') (frequency: 25)\n",
      "Merge 467: ('tic', '</w>') (frequency: 25)\n",
      "Merge 468: ('model', '</w>') (frequency: 25)\n",
      "Merge 469: ('v', '</w>') (frequency: 25)\n",
      "Merge 470: ('ol', 'u') (frequency: 24)\n",
      "Merge 471: ('f', 'e') (frequency: 24)\n",
      "Merge 472: ('con', 'sid') (frequency: 24)\n",
      "Merge 473: ('soci', 'o') (frequency: 24)\n",
      "Merge 474: ('tr', 'i') (frequency: 24)\n",
      "Merge 475: ('t', 'a') (frequency: 24)\n",
      "Merge 476: ('righ', 'ts</w>') (frequency: 24)\n",
      "Merge 477: ('nat', 'ural</w>') (frequency: 24)\n",
      "Merge 478: ('out', 'puts</w>') (frequency: 24)\n",
      "Merge 479: ('examp', 'le</w>') (frequency: 24)\n",
      "Merge 480: ('ic', 's</w>') (frequency: 24)\n",
      "Merge 481: ('en', 's') (frequency: 24)\n",
      "Merge 482: ('st', 'u') (frequency: 24)\n",
      "Merge 483: ('ci', 'pl') (frequency: 24)\n",
      "Merge 484: ('ti', 'v') (frequency: 24)\n",
      "Merge 485: ('b', 'ec') (frequency: 24)\n",
      "Merge 486: ('si', 'm') (frequency: 24)\n",
      "Merge 487: ('human', 's</w>') (frequency: 24)\n",
      "Merge 488: ('ap', 'pl') (frequency: 24)\n",
      "Merge 489: ('c', 'ri') (frequency: 24)\n",
      "Merge 490: ('on', 's</w>') (frequency: 24)\n",
      "Merge 491: ('a', 'ut') (frequency: 24)\n",
      "Merge 492: ('co', 'll') (frequency: 24)\n",
      "Merge 493: ('or', 's</w>') (frequency: 23)\n",
      "Merge 494: ('socio', 'technical</w>') (frequency: 23)\n",
      "Merge 495: ('ar', 'i') (frequency: 23)\n",
      "Merge 496: ('str', 'uc') (frequency: 23)\n",
      "Merge 497: ('d', 'ec') (frequency: 23)\n",
      "Merge 498: ('imp', 'ort') (frequency: 23)\n",
      "Merge 499: ('cour', 'tes') (frequency: 23)\n",
      "Merge 500: ('courtes', 'y</w>') (frequency: 23)\n",
      "\n",
      "Training complete!\n",
      "Final vocabulary size: 3478\n",
      "Number of merges performed: 500\n"
     ]
    }
   ],
   "source": [
    "def train_bpe(vocab, num_merges):\n",
    "    bpe_merges = []\n",
    "    \n",
    "    for i in range(num_merges):\n",
    "        pair_freqs = get_pair_frequencies(vocab)\n",
    "        \n",
    "        if not pair_freqs:\n",
    "            print(f\"No more pairs to merge. Stopped at iteration {i}\")\n",
    "            break\n",
    "        \n",
    "        most_frequent_pair = max(pair_freqs.items(), key=lambda x: x[1])\n",
    "        pair, freq = most_frequent_pair\n",
    "        \n",
    "        print(f\"Merge {i + 1}: {pair} (frequency: {freq})\")\n",
    "        \n",
    "        vocab = merge_pair(pair, vocab)\n",
    "        bpe_merges.append(pair)\n",
    "    \n",
    "    return vocab, bpe_merges\n",
    "\n",
    "num_merges = 500\n",
    "final_vocab, bpe_merges = train_bpe(vocab, num_merges)\n",
    "\n",
    "print(f\"\\nTraining complete!\")\n",
    "print(f\"Final vocabulary size: {len(final_vocab)}\")\n",
    "print(f\"Number of merges performed: {len(bpe_merges)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330b7c42-d5df-4039-a8e8-d97ec4139665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization examples:\n",
      "'language' -> ['language</w>']\n",
      "'amazing' -> ['a', 'ma', 'z', 'ing</w>']\n",
      "'transformers' -> ['trans', 'form', 'ers</w>']\n"
     ]
    }
   ],
   "source": [
    "def apply_bpe(word, merges):\n",
    "    # Start with character-level tokens plus end-of-word marker\n",
    "    tokens = list(word) + ['</w>']\n",
    "    \n",
    "    for merge_pair in merges:\n",
    "        new_tokens = []\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(tokens):\n",
    "            if i < len(tokens) - 1 and (tokens[i], tokens[i + 1]) == merge_pair:\n",
    "                # Apply merge\n",
    "                merged_token = tokens[i] + tokens[i + 1]\n",
    "                new_tokens.append(merged_token)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_tokens.append(tokens[i])\n",
    "                i += 1\n",
    "        \n",
    "        tokens = new_tokens\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Test tokenization with example words\n",
    "test_words = [\"language\", \"amazing\", \"transformers\"]\n",
    "\n",
    "print(\"Tokenization examples:\")\n",
    "tokenized_examples = {}\n",
    "for word in test_words:\n",
    "    tokens = apply_bpe(word, bpe_merges)\n",
    "    tokenized_examples[word] = tokens\n",
    "    print(f\"'{word}' -> {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbb95e8d-5a14-49a6-b128-b099dcf06934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detokenization examples:\n",
      "['language</w>'] -> 'language'\n",
      "Original: 'language', Reconstructed: 'language', Match: True\n",
      "['a', 'ma', 'z', 'ing</w>'] -> 'amazing'\n",
      "Original: 'amazing', Reconstructed: 'amazing', Match: True\n",
      "['trans', 'form', 'ers</w>'] -> 'transformers'\n",
      "Original: 'transformers', Reconstructed: 'transformers', Match: True\n"
     ]
    }
   ],
   "source": [
    "def detokenize(tokens):\n",
    "    # Join tokens and remove end-of-word markers\n",
    "    word = ''.join(tokens)\n",
    "    word = word.replace('</w>', '')\n",
    "    return word\n",
    "\n",
    "print(\"Detokenization examples:\")\n",
    "for word, tokens in tokenized_examples.items():\n",
    "    detokenized = detokenize(tokens)\n",
    "    print(f\"{tokens} -> '{detokenized}'\")\n",
    "    print(f\"Original: '{word}', Reconstructed: '{detokenized}', Match: {word == detokenized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4370d939-b47b-4187-a94c-56508bd190ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token vocabulary created!\n",
      "Total unique tokens: 520\n",
      "\n",
      "Top 10 most frequent tokens with IDs:\n",
      "ID 0: 'the</w>' (frequency: 689)\n",
      "ID 1: 'of</w>' (frequency: 684)\n",
      "ID 2: 'and</w>' (frequency: 610)\n",
      "ID 3: 'a</w>' (frequency: 472)\n",
      "ID 4: 'in' (frequency: 444)\n",
      "ID 5: 'to</w>' (frequency: 431)\n",
      "ID 6: 's' (frequency: 426)\n",
      "ID 7: 'm' (frequency: 413)\n",
      "ID 8: 's</w>' (frequency: 409)\n",
      "ID 9: 'in</w>' (frequency: 397)\n"
     ]
    }
   ],
   "source": [
    "def create_token_vocab(final_vocab):\n",
    "    # Collect all unique tokens\n",
    "    all_tokens = set()\n",
    "    token_frequencies = defaultdict(int)\n",
    "    \n",
    "    for word_tokens, freq in final_vocab.items():\n",
    "        for token in word_tokens:\n",
    "            all_tokens.add(token)\n",
    "            token_frequencies[token] += freq\n",
    "    \n",
    "    # Sort tokens by frequency (most frequent first)\n",
    "    sorted_tokens = sorted(token_frequencies.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create token-to-ID and ID-to-token mappings\n",
    "    token_to_id = {}\n",
    "    id_to_token = {}\n",
    "    \n",
    "    for i, (token, freq) in enumerate(sorted_tokens):\n",
    "        token_to_id[token] = i\n",
    "        id_to_token[i] = token\n",
    "    \n",
    "    return token_to_id, id_to_token, token_frequencies\n",
    "\n",
    "token_to_id, id_to_token, token_frequencies = create_token_vocab(final_vocab)\n",
    "\n",
    "print(\"Token vocabulary created!\")\n",
    "print(f\"Total unique tokens: {len(token_to_id)}\")\n",
    "print(\"\\nTop 10 most frequent tokens with IDs:\")\n",
    "for i in range(min(10, len(id_to_token))):\n",
    "    token = id_to_token[i]\n",
    "    freq = token_frequencies[token]\n",
    "    print(f\"ID {i}: '{token}' (frequency: {freq})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f66236a6-428a-45db-9656-6aa55f5606bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization with IDs:\n",
      "'language':\n",
      "  Tokens: ['language</w>']\n",
      "  IDs: [157]\n",
      "'amazing':\n",
      "  Tokens: ['a', 'ma', 'z', 'ing</w>']\n",
      "  IDs: [19, 82, 107, 14]\n",
      "'transformers':\n",
      "  Tokens: ['trans', 'form', 'ers</w>']\n",
      "  IDs: [208, 295, 193]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_to_ids(word, merges, token_to_id):\n",
    "    # Get string tokens first\n",
    "    string_tokens = apply_bpe(word, merges)\n",
    "    \n",
    "    # Convert to IDs\n",
    "    token_ids = []\n",
    "    for token in string_tokens:\n",
    "        if token in token_to_id:\n",
    "            token_ids.append(token_to_id[token])\n",
    "        else:\n",
    "            # Handle unknown tokens (shouldn't happen with proper training)\n",
    "            print(f\"Warning: Unknown token '{token}' encountered\")\n",
    "            token_ids.append(token_to_id.get('<UNK>', -1))\n",
    "    \n",
    "    return string_tokens, token_ids\n",
    "\n",
    "print(\"\\nTokenization with IDs:\")\n",
    "for word in test_words:\n",
    "    string_tokens, token_ids = tokenize_to_ids(word, bpe_merges, token_to_id)\n",
    "    print(f\"'{word}':\")\n",
    "    print(f\"  Tokens: {string_tokens}\")\n",
    "    print(f\"  IDs: {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcae6b82-4af4-4e40-ab2d-e61ad2010e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detokenization from IDs:\n",
      "IDs [157] -> 'language'\n",
      "Original: 'language', Reconstructed: 'language', Match: True\n",
      "IDs [19, 82, 107, 14] -> 'amazing'\n",
      "Original: 'amazing', Reconstructed: 'amazing', Match: True\n",
      "IDs [208, 295, 193] -> 'transformers'\n",
      "Original: 'transformers', Reconstructed: 'transformers', Match: True\n"
     ]
    }
   ],
   "source": [
    "def detokenize_from_ids(token_ids, id_to_token):\n",
    "    # Convert IDs back to string tokens\n",
    "    string_tokens = []\n",
    "    for token_id in token_ids:\n",
    "        if token_id in id_to_token:\n",
    "            string_tokens.append(id_to_token[token_id])\n",
    "        else:\n",
    "            print(f\"Warning: Unknown token ID {token_id}\")\n",
    "            string_tokens.append('<UNK>')\n",
    "    \n",
    "    # Detokenize string tokens\n",
    "    word = detokenize(string_tokens)\n",
    "    return string_tokens, word\n",
    "\n",
    "print(\"\\nDetokenization from IDs:\")\n",
    "for word in test_words:\n",
    "    string_tokens, token_ids = tokenize_to_ids(word, bpe_merges, token_to_id)\n",
    "    reconstructed_tokens, reconstructed_word = detokenize_from_ids(token_ids, id_to_token)\n",
    "    print(f\"IDs {token_ids} -> '{reconstructed_word}'\")\n",
    "    print(f\"Original: '{word}', Reconstructed: '{reconstructed_word}', Match: {word == reconstructed_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "652c7966-b58d-4bc7-93c1-ddf95f1b0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to bpe_tokenizer.txt\n"
     ]
    }
   ],
   "source": [
    "def save_tokenizer(token_to_id, id_to_token, bpe_merges, filename=\"bpe_tokenizer.txt\"):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        # Save merges\n",
    "        f.write(\"MERGES\\n\")\n",
    "        for pair in bpe_merges:\n",
    "            f.write(f\"{pair[0]} {pair[1]}\\n\")\n",
    "        \n",
    "        # Save vocabulary\n",
    "        f.write(\"VOCAB\\n\")\n",
    "        for token_id, token in id_to_token.items():\n",
    "            f.write(f\"{token} {token_id}\\n\")\n",
    "    \n",
    "    print(f\"Tokenizer saved to {filename}\")\n",
    "\n",
    "def load_tokenizer(filename=\"bpe_tokenizer.txt\"):\n",
    "    bpe_merges = []\n",
    "    token_to_id = {}\n",
    "    id_to_token = {}\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    mode = None\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line == \"MERGES\":\n",
    "            mode = \"merges\"\n",
    "            continue\n",
    "        elif line == \"VOCAB\":\n",
    "            mode = \"vocab\"\n",
    "            continue\n",
    "        \n",
    "        if mode == \"merges\" and line:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 2:\n",
    "                bpe_merges.append((parts[0], parts[1]))\n",
    "        elif mode == \"vocab\" and line:\n",
    "            parts = line.rsplit(' ', 1)  # Split from right to handle tokens with spaces\n",
    "            if len(parts) == 2:\n",
    "                token, token_id = parts[0], int(parts[1])\n",
    "                token_to_id[token] = token_id\n",
    "                id_to_token[token_id] = token\n",
    "    \n",
    "    return token_to_id, id_to_token, bpe_merges\n",
    "\n",
    "# Save the trained tokenizer\n",
    "save_tokenizer(token_to_id, id_to_token, bpe_merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c292c7b-a90d-4bf9-b1e8-210a7cfad2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
